{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e14dc2e9-adde-418f-9ab2-25afa0ff382c",
   "metadata": {},
   "source": [
    "Q1. What is Gradient Boosting Regression?\n",
    "\n",
    "Gradient Boosting Regression: An ensemble machine learning technique that builds a model from weak learners, typically decision trees, in a stage-wise manner. Each new tree is trained to correct the residual errors of the combined ensemble of previous trees, thereby improving accuracy.\n",
    "Q2. Simple Gradient Boosting Algorithm from Scratch\n",
    "\n",
    "Here's a simple implementation of a gradient boosting algorithm using Python and NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40d841d0-9858-4e4d-ae45-2a8fd5bf9dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.27839675798649904\n",
      "R-squared: 0.8673290326026977\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "class SimpleGradientBoostingRegressor:\n",
    "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=3):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.models = []\n",
    "        self.initial_pred = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.initial_pred = np.mean(y)\n",
    "        residuals = y - self.initial_pred\n",
    "        \n",
    "        for _ in range(self.n_estimators):\n",
    "            tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            tree.fit(X, residuals)\n",
    "            pred = tree.predict(X)\n",
    "            residuals -= self.learning_rate * pred\n",
    "            self.models.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = np.full(X.shape[0], self.initial_pred)\n",
    "        for tree in self.models:\n",
    "            y_pred += self.learning_rate * tree.predict(X)\n",
    "        return y_pred\n",
    "\n",
    "# Example dataset\n",
    "X = np.array([[1], [2], [3], [4], [5]])\n",
    "y = np.array([1.2, 1.9, 3.2, 4.3, 5.1])\n",
    "\n",
    "# Train the model\n",
    "model = SimpleGradientBoostingRegressor(n_estimators=10, learning_rate=0.1, max_depth=2)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "r2 = r2_score(y, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3219a2ee-763b-4494-a694-f8836dff6a01",
   "metadata": {},
   "source": [
    "Q3. Experiment with Different Hyperparameters\n",
    "\n",
    "Here's how you can use grid search to find the best hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dab5743-7f59-4db3-a099-33f2b71fe956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 100}\n",
      "Best Score: 1.5500000266301834\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [1, 2, 3]\n",
    "}\n",
    "\n",
    "# Define the model\n",
    "model = SimpleGradientBoostingRegressor()\n",
    "\n",
    "# Implementing GridSearchCV is not straightforward with a custom class,\n",
    "# So we'll use sklearn's GradientBoostingRegressor for demonstration purposes\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Define the model\n",
    "model = GradientBoostingRegressor()\n",
    "\n",
    "# Implement GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Score: {-grid_search.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d82af05-dc9c-4ddd-80e0-3641aef76464",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
